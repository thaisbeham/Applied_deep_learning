{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thaisbeham/Applied_deep_learning/blob/main/Assigment2_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM - Fake News detection\n",
        "\n",
        "Fake - 0\n",
        "Real - 1"
      ],
      "metadata": {
        "id": "OzFQgCpKtafy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vvy4rxvLKY6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfzdqQ4HKfSE",
        "outputId": "7051e401-9f56-4826-eb0f-6c3fc00f4147"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "#from utils import merge_datasets, smaller_set\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from matplotlib import pyplot as plt\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding,Dense,LSTM,Dropout,Flatten,BatchNormalization,Conv1D,GlobalMaxPooling1D,MaxPooling1D, GlobalAveragePooling1D\n",
        "from keras.optimizers import  SGD\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import Adam\n",
        "from keras import regularizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.preprocessing import sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#from hyperas.distributions import uniform\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras import regularizers\n",
        "import string\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing import sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "91HtHS8vKXCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions"
      ],
      "metadata": {
        "id": "ZeEUBxOQsDWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_news(path, column_text_name):\n",
        "  news = pd.read_csv(path)\n",
        "  news[column_text_name] = news[column_text_name].astype(str)\n",
        "  if column_text_name != \"text\":\n",
        "    news.rename(columns = {column_text_name : \"text\"}, inplace = True)\n",
        "\n",
        "  return news\n",
        "\n",
        "def merge_split_datasets(real, fake, n_testsize = 0.15):\n",
        "  # take 13000 rows from real data\n",
        "  #real = real.sample(n = 13000, random_state= 2, axis = 0)\n",
        "\n",
        "  # add column label\n",
        "  real['label'] = 1\n",
        "  fake['label'] = 0\n",
        "\n",
        "  real = real[['text', 'label']]\n",
        "  fake = fake[['text', 'label']]\n",
        "  \n",
        "  #merge real and fake\n",
        "  # use only the sentence column on fake\n",
        "  merged = pd.DataFrame(real.append(fake, ignore_index = True))\n",
        "  merged = merged.dropna()\n",
        " \n",
        "  merged = merged.sample(frac = 1, random_state= 1, ignore_index = True)#.reset_index()\n",
        "\n",
        "  train, test = train_test_split(merged, test_size = n_testsize, random_state = 1)\n",
        "\n",
        "  X_test = test['text']\n",
        "  Y_test = test['label']\n",
        "\n",
        "  #create validation set\n",
        "  X = train['text']\n",
        "  Y = train['label'].astype(int)    \n",
        "  X_train,X_valid,Y_train,Y_valid = train_test_split(X,Y,test_size=0.15, random_state=42)\n",
        "\n",
        "  return X_train, Y_train, X_valid, Y_valid, X_test, Y_test\n",
        "\n",
        "\n",
        "def RNN():\n",
        "  inputs = Input(name='inputs',shape=[max_len])\n",
        "  layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
        "  layer = LSTM(64)(layer)\n",
        "  layer = Dense(256,name='FC1')(layer)\n",
        "  layer = Activation('relu')(layer)\n",
        "  layer = Dropout(0.5)(layer)\n",
        "  layer = Dense(1,name='out_layer')(layer)\n",
        "  layer = Activation('sigmoid')(layer)\n",
        "  model = Model(inputs=inputs,outputs=layer)\n",
        "  return model\n",
        "\n",
        "def predict_result(X_test, Y_test, tok):\n",
        "  test_sequences = tok.texts_to_sequences(X_test)\n",
        "  test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n",
        "  accr = model.evaluate(test_sequences_matrix,Y_test)\n",
        "  print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n",
        "  predict_labels = model.predict(test_sequences_matrix) \n",
        "\n",
        "  # convert the range predicition into 0s or 1s\n",
        "  Y_pred =[ 1 if i>0.5 else 0 for i in predict_labels  ] \n",
        "\n",
        "  print(\"Number Real news:\",sum(Y_pred))\n",
        "  print(\"Number Fake news:\",len(Y_pred)-sum(Y_pred))\n",
        "  print()\n",
        "  print(\"Classification Report\")\n",
        "  print(classification_report(Y_test, Y_pred, target_names = ['class 0', 'class 1']))\n",
        "  print()\n",
        "  print(\"Confusion Matrix\")\n",
        "  matrix=confusion_matrix(Y_test,Y_pred,labels=[0,1])\n",
        "  cm=pd.DataFrame(matrix,index=['class_0 pred','class_1 pred'],columns=['class_0 True','class_1 True'])\n",
        "  print(cm)\n",
        "  return\n",
        "\n",
        "def trainer(X_train, Y_train, max_words, max_len, n_batchsize, n_epochs, model):\n",
        "  tok = Tokenizer(num_words=max_words)\n",
        "  tok.fit_on_texts(X_train)\n",
        "  sequences = tok.texts_to_sequences(X_train)\n",
        "  sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n",
        "  \n",
        "  model.summary()\n",
        "  model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])\n",
        "  model.fit(sequences_matrix,Y_train,batch_size=n_batchsize,epochs=n_epochs,\n",
        "          validation_split=0.2)\n",
        "  \n",
        "  return model, tok\n",
        "\n"
      ],
      "metadata": {
        "id": "JKzSXRq2lSJ4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read datasets"
      ],
      "metadata": {
        "id": "9ceouWvH4YrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read datasets\n",
        "fake_news1 = read_news(\"/content/drive/MyDrive/dados_/fake.csv\", \"text\")\n",
        "fake_news2 = read_news(\"/content/drive/MyDrive/dados_/Fake_bisaillon.csv\", \"text\")\n",
        "\n",
        "real_news1 = read_news(\"/content/drive/MyDrive/dados_/df_2016.csv\", \"sentence\")\n",
        "real_news2 = read_news(\"/content/drive/MyDrive/dados_/True_bisaillon.csv\", \"text\")\n",
        "\n",
        "#shape of each dataset\n",
        "print(\"fake_news1: \", np.shape(fake_news1), \"\\nfake_news2: \",  np.shape(fake_news2), \"\\nreal_news1: \",  np.shape(real_news1),\"\\nreal_news2: \", np.shape(real_news2)  )\n",
        "\n",
        "real_news1_ = real_news1.sample(n = 15000, random_state= 2, axis = 0)\n",
        "\n",
        "\n",
        "# separate the location of the news from the news text (e.g. \"WASHINGTON (Reuters)\")\n",
        "real_news2[[\"loc\", \"text\"]] = real_news2['text'].str.split('-',1, expand = True)\n",
        "#real_news2.head()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv6G6AP6TXRN",
        "outputId": "655fc99f-2f54-47b5-dde8-234cbf8ef396"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fake_news1:  (12999, 20) \n",
            "fake_news2:  (23481, 4) \n",
            "real_news1:  (105606, 3) \n",
            "real_news2:  (21417, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train model with 2 datasets**\n",
        "\n",
        "> Dataset fake.csv and df_2016.csv\n"
      ],
      "metadata": {
        "id": "UBSus53f72RD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train, X_valid, Y_valid, X_test, Y_test = merge_split_datasets(real_news1, fake_news1)"
      ],
      "metadata": {
        "id": "IUb82hpo71ku"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parameters tunning"
      ],
      "metadata": {
        "id": "PhbcwCGj83Lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 1000\n",
        "max_len = 150\n",
        "n_batchsize = 128\n",
        "n_epochs = 10"
      ],
      "metadata": {
        "id": "DYSQnx5k86_b"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train"
      ],
      "metadata": {
        "id": "1nTIOgOY9In6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN()\n",
        "\n",
        "trained_model, tok = trainer(X_train, Y_train, max_words = max_words, max_len = max_len, n_batchsize = n_batchsize, n_epochs = n_epochs, model = model)"
      ],
      "metadata": {
        "id": "o1jt7DSY9IR0",
        "outputId": "0300faba-9105-4c93-8cba-7e1774ab6338",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 150)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 150, 50)           50000     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                29440     \n",
            "                                                                 \n",
            " FC1 (Dense)                 (None, 256)               16640     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " out_layer (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 96,337\n",
            "Trainable params: 96,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "127/127 [==============================] - 9s 19ms/step - loss: 0.1990 - accuracy: 0.9276 - val_loss: 0.1152 - val_accuracy: 0.9639\n",
            "Epoch 2/10\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.0986 - accuracy: 0.9663 - val_loss: 0.0860 - val_accuracy: 0.9686\n",
            "Epoch 3/10\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.0790 - accuracy: 0.9718 - val_loss: 0.0837 - val_accuracy: 0.9703\n",
            "Epoch 4/10\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 0.0697 - accuracy: 0.9742 - val_loss: 0.0849 - val_accuracy: 0.9711\n",
            "Epoch 5/10\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.0633 - accuracy: 0.9772 - val_loss: 0.0931 - val_accuracy: 0.9728\n",
            "Epoch 6/10\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 0.0574 - accuracy: 0.9794 - val_loss: 0.0899 - val_accuracy: 0.9713\n",
            "Epoch 7/10\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.0524 - accuracy: 0.9803 - val_loss: 0.0871 - val_accuracy: 0.9701\n",
            "Epoch 8/10\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.0467 - accuracy: 0.9821 - val_loss: 0.1060 - val_accuracy: 0.9736\n",
            "Epoch 9/10\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 0.0427 - accuracy: 0.9842 - val_loss: 0.0990 - val_accuracy: 0.9718\n",
            "Epoch 10/10\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.0392 - accuracy: 0.9858 - val_loss: 0.1230 - val_accuracy: 0.9671\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predict - Valid set"
      ],
      "metadata": {
        "id": "fPD5h7X5-Lbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_result(X_valid, Y_valid, tok)"
      ],
      "metadata": {
        "id": "bQ-1RJsU-MB_",
        "outputId": "3cf28657-22b0-4153-c70e-5fef941716e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112/112 [==============================] - 1s 6ms/step - loss: 0.1543 - accuracy: 0.9630\n",
            "Test set\n",
            "  Loss: 0.154\n",
            "  Accuracy: 0.963\n",
            "112/112 [==============================] - 1s 5ms/step\n",
            "Number Real news: 1964\n",
            "Number Fake news: 1606\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.96      0.96      0.96      1606\n",
            "     class 1       0.97      0.97      0.97      1964\n",
            "\n",
            "    accuracy                           0.96      3570\n",
            "   macro avg       0.96      0.96      0.96      3570\n",
            "weighted avg       0.96      0.96      0.96      3570\n",
            "\n",
            "\n",
            "Confusion Matrix\n",
            "              class_0 True  class_1 True\n",
            "class_0 pred          1540            66\n",
            "class_1 pred            66          1898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predict - Test set"
      ],
      "metadata": {
        "id": "LP0MiIH0-Mf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_result(X_test, Y_test, tok)"
      ],
      "metadata": {
        "id": "dYETNYTv-NDl",
        "outputId": "9845698a-52ac-4641-968e-cddb7ba98e17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132/132 [==============================] - 1s 6ms/step - loss: 0.1570 - accuracy: 0.9602\n",
            "Test set\n",
            "  Loss: 0.157\n",
            "  Accuracy: 0.960\n",
            "132/132 [==============================] - 0s 4ms/step\n",
            "Number Real news: 2265\n",
            "Number Fake news: 1935\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.95      0.96      0.96      1920\n",
            "     class 1       0.97      0.96      0.96      2280\n",
            "\n",
            "    accuracy                           0.96      4200\n",
            "   macro avg       0.96      0.96      0.96      4200\n",
            "weighted avg       0.96      0.96      0.96      4200\n",
            "\n",
            "\n",
            "Confusion Matrix\n",
            "              class_0 True  class_1 True\n",
            "class_0 pred          1844            76\n",
            "class_1 pred            91          2189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train model with  4 datasets**\n",
        "\n",
        "> Datasets: fake.csv, df_2016.csv, fake_Bisallion.csv and True_Bisallion.csv"
      ],
      "metadata": {
        "id": "UdvQVk6Y7xZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "real_news = pd.DataFrame(real_news1[\"text\"].append(real_news2[\"text\"], ignore_index = True))\n",
        "fake_news = pd.DataFrame(fake_news1[\"text\"].append(fake_news2[\"text\"], ignore_index = True))\n",
        "X_train, Y_train, X_valid, Y_valid, X_test, Y_test = merge_split_datasets(real_news, fake_news)"
      ],
      "metadata": {
        "id": "B092VQVap4te"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parameters tunning"
      ],
      "metadata": {
        "id": "sM0R6v1j4npk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 1000\n",
        "max_len = 150\n",
        "n_batchsize = 128\n",
        "n_epochs = 10\n"
      ],
      "metadata": {
        "id": "3QxJV4OtW42Z"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train model"
      ],
      "metadata": {
        "id": "K3np9KxP4wbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN()\n",
        "\n",
        "trained_model, tok = trainer(X_train, Y_train, max_words = max_words, max_len = max_len, n_batchsize = n_batchsize, n_epochs = n_epochs, model = model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwChq8wbW_bt",
        "outputId": "1e5b1545-18da-4864-8b67-9c64cbb6fe79"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 150)]             0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 150, 50)           50000     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                29440     \n",
            "                                                                 \n",
            " FC1 (Dense)                 (None, 256)               16640     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " out_layer (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 96,337\n",
            "Trainable params: 96,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "330/330 [==============================] - 8s 19ms/step - loss: 0.2253 - accuracy: 0.9129 - val_loss: 0.1657 - val_accuracy: 0.9455\n",
            "Epoch 2/10\n",
            "330/330 [==============================] - 4s 13ms/step - loss: 0.1466 - accuracy: 0.9475 - val_loss: 0.1823 - val_accuracy: 0.9314\n",
            "Epoch 3/10\n",
            "330/330 [==============================] - 4s 13ms/step - loss: 0.1325 - accuracy: 0.9524 - val_loss: 0.1507 - val_accuracy: 0.9500\n",
            "Epoch 4/10\n",
            "330/330 [==============================] - 4s 13ms/step - loss: 0.1217 - accuracy: 0.9564 - val_loss: 0.1455 - val_accuracy: 0.9483\n",
            "Epoch 5/10\n",
            "330/330 [==============================] - 4s 13ms/step - loss: 0.1105 - accuracy: 0.9597 - val_loss: 0.2300 - val_accuracy: 0.9398\n",
            "Epoch 6/10\n",
            "330/330 [==============================] - 5s 14ms/step - loss: 0.1001 - accuracy: 0.9632 - val_loss: 0.1642 - val_accuracy: 0.9454\n",
            "Epoch 7/10\n",
            "330/330 [==============================] - 4s 13ms/step - loss: 0.0960 - accuracy: 0.9654 - val_loss: 0.1395 - val_accuracy: 0.9514\n",
            "Epoch 8/10\n",
            "330/330 [==============================] - 5s 14ms/step - loss: 0.0891 - accuracy: 0.9676 - val_loss: 0.1437 - val_accuracy: 0.9491\n",
            "Epoch 9/10\n",
            "330/330 [==============================] - 4s 13ms/step - loss: 0.0852 - accuracy: 0.9694 - val_loss: 0.2023 - val_accuracy: 0.9485\n",
            "Epoch 10/10\n",
            "330/330 [==============================] - 4s 13ms/step - loss: 0.0814 - accuracy: 0.9708 - val_loss: 0.1389 - val_accuracy: 0.9558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predict - Valid set"
      ],
      "metadata": {
        "id": "zkla5Kgz41cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_result(X_valid, Y_valid, tok)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wSmSyeTxCPQ",
        "outputId": "35e820b0-4373-4df2-e634-5d416e854134"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 5ms/step - loss: 0.1416 - accuracy: 0.9580\n",
            "Test set\n",
            "  Loss: 0.142\n",
            "  Accuracy: 0.958\n",
            "291/291 [==============================] - 1s 4ms/step\n",
            "Number Real news: 4889\n",
            "Number Fake news: 4405\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.98      0.94      0.96      4593\n",
            "     class 1       0.94      0.98      0.96      4701\n",
            "\n",
            "    accuracy                           0.96      9294\n",
            "   macro avg       0.96      0.96      0.96      9294\n",
            "weighted avg       0.96      0.96      0.96      9294\n",
            "\n",
            "\n",
            "Confusion Matrix\n",
            "              class_0 True  class_1 True\n",
            "class_0 pred          4304           289\n",
            "class_1 pred           101          4600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predict - test set"
      ],
      "metadata": {
        "id": "1aH96O7D46bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_result(X_test, Y_test, tok)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV50mB5euziX",
        "outputId": "9ca19453-9ebd-434e-c0f1-b5930414b94e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "342/342 [==============================] - 2s 5ms/step - loss: 0.1330 - accuracy: 0.9570\n",
            "Test set\n",
            "  Loss: 0.133\n",
            "  Accuracy: 0.957\n",
            "342/342 [==============================] - 1s 4ms/step\n",
            "Number Real news: 5707\n",
            "Number Fake news: 5228\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.97      0.94      0.96      5406\n",
            "     class 1       0.94      0.97      0.96      5529\n",
            "\n",
            "    accuracy                           0.96     10935\n",
            "   macro avg       0.96      0.96      0.96     10935\n",
            "weighted avg       0.96      0.96      0.96     10935\n",
            "\n",
            "\n",
            "Confusion Matrix\n",
            "              class_0 True  class_1 True\n",
            "class_0 pred          5082           324\n",
            "class_1 pred           146          5383\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}