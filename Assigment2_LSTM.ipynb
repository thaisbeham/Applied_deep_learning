{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thaisbeham/Applied_deep_learning/blob/main/Assigment2_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM - Fake News detection\n",
        "\n",
        "Fake - 0\n",
        "Real - 1"
      ],
      "metadata": {
        "id": "OzFQgCpKtafy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vvy4rxvLKY6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfzdqQ4HKfSE",
        "outputId": "7051e401-9f56-4826-eb0f-6c3fc00f4147"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "#from utils import merge_datasets, smaller_set\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from matplotlib import pyplot as plt\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding,Dense,LSTM,Dropout,Flatten,BatchNormalization,Conv1D,GlobalMaxPooling1D,MaxPooling1D, GlobalAveragePooling1D\n",
        "from keras.optimizers import  SGD\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import Adam\n",
        "from keras import regularizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.preprocessing import sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#from hyperas.distributions import uniform\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras import regularizers\n",
        "import string\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing import sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "91HtHS8vKXCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions"
      ],
      "metadata": {
        "id": "ZeEUBxOQsDWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_news(path, column_text_name):\n",
        "  news = pd.read_csv(path)\n",
        "  news[column_text_name] = news[column_text_name].astype(str)\n",
        "  if column_text_name != \"text\":\n",
        "    news.rename(columns = {column_text_name : \"text\"}, inplace = True)\n",
        "\n",
        "  return news\n",
        "\n",
        "def merge_split_datasets(real, fake, n_testsize = 0.15):\n",
        "  # take 13000 rows from real data\n",
        "  #real = real.sample(n = 13000, random_state= 2, axis = 0)\n",
        "\n",
        "  # add column label\n",
        "  real['label'] = 1\n",
        "  fake['label'] = 0\n",
        "\n",
        "  real = real[['text', 'label']]\n",
        "  fake = fake[['text', 'label']]\n",
        "  \n",
        "  #merge real and fake\n",
        "  # use only the sentence column on fake\n",
        "  merged = pd.DataFrame(real.append(fake, ignore_index = True))\n",
        "  merged = merged.dropna()\n",
        " \n",
        "  merged = merged.sample(frac = 1, random_state= 1, ignore_index = True)#.reset_index()\n",
        "\n",
        "  train, test = train_test_split(merged, test_size = n_testsize, random_state = 1)\n",
        "\n",
        "  X_test = test['text']\n",
        "  Y_test = test['label']\n",
        "\n",
        "  #create validation set\n",
        "  X = train['text']\n",
        "  Y = train['label'].astype(int)    \n",
        "  X_train,X_valid,Y_train,Y_valid = train_test_split(X,Y,test_size=0.15, random_state=42)\n",
        "\n",
        "  return X_train, Y_train, X_valid, Y_valid, X_test, Y_test\n",
        "\n",
        "\n",
        "def RNN(max_tokens, max_len, dropout):\n",
        "  inputs = Input(name='inputs',shape=[max_len])\n",
        "  layer = Embedding(max_tokens,50,input_length=max_len)(inputs)\n",
        "  layer = LSTM(64)(layer)\n",
        "  layer = Dense(256,name='FC1')(layer)\n",
        "  layer = Activation('relu')(layer)\n",
        "  layer = Dropout(dropout)(layer)\n",
        "  layer = Dense(1,name='out_layer')(layer)\n",
        "  layer = Activation('sigmoid')(layer)\n",
        "  model = Model(inputs=inputs,outputs=layer)\n",
        "  return model\n",
        "\n",
        "def predict_result(X_test, Y_test, tok):\n",
        "  test_sequences = tok.texts_to_sequences(X_test)\n",
        "  test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n",
        "  accr = model.evaluate(test_sequences_matrix,Y_test)\n",
        "  print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n",
        "  predict_labels = model.predict(test_sequences_matrix) \n",
        "\n",
        "  # convert the range predicition into 0s or 1s\n",
        "  Y_pred =[ 1 if i>0.5 else 0 for i in predict_labels  ] \n",
        "\n",
        "  print(\"Number Real news:\",sum(Y_pred))\n",
        "  print(\"Number Fake news:\",len(Y_pred)-sum(Y_pred))\n",
        "  print()\n",
        "  print(\"Classification Report\")\n",
        "  print(classification_report(Y_test, Y_pred, target_names = ['class 0', 'class 1']))\n",
        "  print()\n",
        "  print(\"Confusion Matrix\")\n",
        "  matrix=confusion_matrix(Y_test,Y_pred,labels=[0,1])\n",
        "  cm=pd.DataFrame(matrix,index=['class_0 pred','class_1 pred'],columns=['class_0 True','class_1 True'])\n",
        "  print(cm)\n",
        "  return\n",
        "\n",
        "def trainer(X_train, Y_train, max_words, max_len, n_batchsize, n_epochs, model):\n",
        "  tok = Tokenizer(num_words=max_words)\n",
        "  tok.fit_on_texts(X_train)\n",
        "  sequences = tok.texts_to_sequences(X_train)\n",
        "  sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n",
        "  \n",
        "  model.summary()\n",
        "  model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])\n",
        "  model.fit(sequences_matrix,Y_train,batch_size=n_batchsize,epochs=n_epochs,\n",
        "          validation_split=0.2)\n",
        "  \n",
        "  return model, tok\n",
        "\n"
      ],
      "metadata": {
        "id": "JKzSXRq2lSJ4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read datasets"
      ],
      "metadata": {
        "id": "9ceouWvH4YrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read datasets\n",
        "fake_news1 = read_news(\"/content/drive/MyDrive/dados_/fake.csv\", \"text\")\n",
        "fake_news2 = read_news(\"/content/drive/MyDrive/dados_/Fake_bisaillon.csv\", \"text\")\n",
        "\n",
        "real_news1 = read_news(\"/content/drive/MyDrive/dados_/df_2016.csv\", \"sentence\")\n",
        "real_news2 = read_news(\"/content/drive/MyDrive/dados_/True_bisaillon.csv\", \"text\")\n",
        "\n",
        "#shape of each dataset\n",
        "print(\"fake_news1: \", np.shape(fake_news1), \"\\nfake_news2: \",  np.shape(fake_news2), \"\\nreal_news1: \",  np.shape(real_news1),\"\\nreal_news2: \", np.shape(real_news2)  )\n",
        "\n",
        "real_news1_smallset = real_news1.sample(n = 15000, random_state= 2, axis = 0)\n",
        "\n",
        "print(\"real_news1 small set:\", np.shape(real_news1_smallset))\n",
        "# separate the location of the news from the news text (e.g. \"WASHINGTON (Reuters)\")\n",
        "real_news2[[\"loc\", \"text\"]] = real_news2['text'].str.split('-',1, expand = True)\n",
        "#real_news2.head()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv6G6AP6TXRN",
        "outputId": "db0dab67-1849-4dff-ed0c-e2fae3a2b0de"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fake_news1:  (12999, 20) \n",
            "fake_news2:  (23481, 4) \n",
            "real_news1:  (105606, 3) \n",
            "real_news2:  (21417, 4)\n",
            "real_news1 small set: (15000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train model with 2 datasets with similar lenght**\n",
        "> Dataset fake.csv and df_2016.csv"
      ],
      "metadata": {
        "id": "f8h7IHbTMNeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train, X_valid, Y_valid, X_test, Y_test = merge_split_datasets(real_news1, fake_news1)"
      ],
      "metadata": {
        "id": "whp8fIVsMMpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parameters tunning"
      ],
      "metadata": {
        "id": "e6gKmUdZMMaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 1000\n",
        "max_len = 300\n",
        "n_batchsize = 128\n",
        "n_epochs = 10"
      ],
      "metadata": {
        "id": "KwfRpNEQNXRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "       \"max_tokens\" : [25, 50],\n",
        "       \"max_len\" : [5, 50],\n",
        "       \"dropout\" : [0.1, 0.2]\n",
        "}\n",
        "\n",
        "modelcv = GridSearchCV(RNN, param_grid, cv = 3, scoring= 'accuracy')\n",
        "modelcv.fit(X_valid, Y_valid)"
      ],
      "metadata": {
        "id": "u6mnphk_REFI",
        "outputId": "8122fc82-4ef1-4692-e5b3-868b52d0513b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-b9d77845a2da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodelcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodelcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mscorers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m             \u001b[0mscorers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0mscorers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_multimetric_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    446\u001b[0m     \"\"\"\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m    449\u001b[0m             \u001b[0;34m\"estimator should be an estimator implementing 'fit' method, %r was passed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: estimator should be an estimator implementing 'fit' method, <function RNN at 0x7fbf4271b4c0> was passed"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train"
      ],
      "metadata": {
        "id": "Q5DuJkpANjBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN()\n",
        "\n",
        "trained_model, tok = trainer(X_train, Y_train, max_words = max_words, max_len = max_len, n_batchsize = n_batchsize, n_epochs = n_epochs, model = model)"
      ],
      "metadata": {
        "id": "SeHUxroRNdJk",
        "outputId": "7f0eb4ca-fbb6-47a1-9f3b-900aca3f8ff0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 150)]             0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 150, 50)           50000     \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 64)                29440     \n",
            "                                                                 \n",
            " FC1 (Dense)                 (None, 256)               16640     \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " out_layer (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 96,337\n",
            "Trainable params: 96,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "330/330 [==============================] - 7s 16ms/step - loss: 0.2227 - accuracy: 0.9150 - val_loss: 0.2068 - val_accuracy: 0.9219\n",
            "Epoch 2/10\n",
            "330/330 [==============================] - 5s 16ms/step - loss: 0.1449 - accuracy: 0.9480 - val_loss: 0.1517 - val_accuracy: 0.9469\n",
            "Epoch 3/10\n",
            "330/330 [==============================] - 5s 14ms/step - loss: 0.1313 - accuracy: 0.9525 - val_loss: 0.1672 - val_accuracy: 0.9445\n",
            "Epoch 4/10\n",
            "330/330 [==============================] - 5s 15ms/step - loss: 0.1194 - accuracy: 0.9571 - val_loss: 0.1652 - val_accuracy: 0.9478\n",
            "Epoch 5/10\n",
            "330/330 [==============================] - 4s 13ms/step - loss: 0.1081 - accuracy: 0.9607 - val_loss: 0.1403 - val_accuracy: 0.9483\n",
            "Epoch 6/10\n",
            "330/330 [==============================] - 6s 17ms/step - loss: 0.1013 - accuracy: 0.9634 - val_loss: 0.1481 - val_accuracy: 0.9466\n",
            "Epoch 7/10\n",
            "330/330 [==============================] - 5s 15ms/step - loss: 0.0939 - accuracy: 0.9656 - val_loss: 0.1614 - val_accuracy: 0.9374\n",
            "Epoch 8/10\n",
            "330/330 [==============================] - 4s 14ms/step - loss: 0.0883 - accuracy: 0.9683 - val_loss: 0.1348 - val_accuracy: 0.9531\n",
            "Epoch 9/10\n",
            "330/330 [==============================] - 4s 14ms/step - loss: 0.0840 - accuracy: 0.9695 - val_loss: 0.1450 - val_accuracy: 0.9547\n",
            "Epoch 10/10\n",
            "330/330 [==============================] - 5s 15ms/step - loss: 0.0785 - accuracy: 0.9726 - val_loss: 0.1321 - val_accuracy: 0.9564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predict - Valid set"
      ],
      "metadata": {
        "id": "AYfBMgFKOMvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_result(X_valid, Y_valid, tok)"
      ],
      "metadata": {
        "id": "hd6gYeY-OMeW",
        "outputId": "f1fc697f-f6c5-45f2-92d4-1694420e1ad8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 5ms/step - loss: 0.1330 - accuracy: 0.9559\n",
            "Test set\n",
            "  Loss: 0.133\n",
            "  Accuracy: 0.956\n",
            "291/291 [==============================] - 1s 4ms/step\n",
            "Number Real news: 4829\n",
            "Number Fake news: 4465\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.97      0.94      0.95      4593\n",
            "     class 1       0.94      0.97      0.96      4701\n",
            "\n",
            "    accuracy                           0.96      9294\n",
            "   macro avg       0.96      0.96      0.96      9294\n",
            "weighted avg       0.96      0.96      0.96      9294\n",
            "\n",
            "\n",
            "Confusion Matrix\n",
            "              class_0 True  class_1 True\n",
            "class_0 pred          4324           269\n",
            "class_1 pred           141          4560\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict - Test set"
      ],
      "metadata": {
        "id": "CsaqkgDsOLwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_result(X_test, Y_test, tok)"
      ],
      "metadata": {
        "id": "CAC_5uWpOLdY",
        "outputId": "38fc86f2-eb1a-4bea-edcc-91599f4eacde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "342/342 [==============================] - 2s 5ms/step - loss: 0.1242 - accuracy: 0.9586\n",
            "Test set\n",
            "  Loss: 0.124\n",
            "  Accuracy: 0.959\n",
            "342/342 [==============================] - 1s 4ms/step\n",
            "Number Real news: 5650\n",
            "Number Fake news: 5285\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.97      0.95      0.96      5406\n",
            "     class 1       0.95      0.97      0.96      5529\n",
            "\n",
            "    accuracy                           0.96     10935\n",
            "   macro avg       0.96      0.96      0.96     10935\n",
            "weighted avg       0.96      0.96      0.96     10935\n",
            "\n",
            "\n",
            "Confusion Matrix\n",
            "              class_0 True  class_1 True\n",
            "class_0 pred          5119           287\n",
            "class_1 pred           166          5363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train model with 2 datasets**\n",
        "\n",
        "> Dataset fake.csv and df_2016.csv\n"
      ],
      "metadata": {
        "id": "UBSus53f72RD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train, X_valid, Y_valid, X_test, Y_test = merge_split_datasets(real_news1, fake_news1)"
      ],
      "metadata": {
        "id": "IUb82hpo71ku"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parameters tunning"
      ],
      "metadata": {
        "id": "PhbcwCGj83Lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 1000\n",
        "max_len = 150\n",
        "n_batchsize = 128\n",
        "n_epochs = 10"
      ],
      "metadata": {
        "id": "DYSQnx5k86_b"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train"
      ],
      "metadata": {
        "id": "1nTIOgOY9In6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN()\n",
        "\n",
        "trained_model, tok = trainer(X_train, Y_train, max_words = max_words, max_len = max_len, n_batchsize = n_batchsize, n_epochs = n_epochs, model = model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1jt7DSY9IR0",
        "outputId": "0300faba-9105-4c93-8cba-7e1774ab6338"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 150)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 150, 50)           50000     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                29440     \n",
            "                                                                 \n",
            " FC1 (Dense)                 (None, 256)               16640     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " out_layer (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 96,337\n",
            "Trainable params: 96,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "127/127 [==============================] - 9s 19ms/step - loss: 0.1990 - accuracy: 0.9276 - val_loss: 0.1152 - val_accuracy: 0.9639\n",
            "Epoch 2/10\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.0986 - accuracy: 0.9663 - val_loss: 0.0860 - val_accuracy: 0.9686\n",
            "Epoch 3/10\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.0790 - accuracy: 0.9718 - val_loss: 0.0837 - val_accuracy: 0.9703\n",
            "Epoch 4/10\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 0.0697 - accuracy: 0.9742 - val_loss: 0.0849 - val_accuracy: 0.9711\n",
            "Epoch 5/10\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.0633 - accuracy: 0.9772 - val_loss: 0.0931 - val_accuracy: 0.9728\n",
            "Epoch 6/10\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 0.0574 - accuracy: 0.9794 - val_loss: 0.0899 - val_accuracy: 0.9713\n",
            "Epoch 7/10\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.0524 - accuracy: 0.9803 - val_loss: 0.0871 - val_accuracy: 0.9701\n",
            "Epoch 8/10\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.0467 - accuracy: 0.9821 - val_loss: 0.1060 - val_accuracy: 0.9736\n",
            "Epoch 9/10\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 0.0427 - accuracy: 0.9842 - val_loss: 0.0990 - val_accuracy: 0.9718\n",
            "Epoch 10/10\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.0392 - accuracy: 0.9858 - val_loss: 0.1230 - val_accuracy: 0.9671\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predict - Valid set"
      ],
      "metadata": {
        "id": "fPD5h7X5-Lbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_result(X_valid, Y_valid, tok)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ-1RJsU-MB_",
        "outputId": "3cf28657-22b0-4153-c70e-5fef941716e5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112/112 [==============================] - 1s 6ms/step - loss: 0.1543 - accuracy: 0.9630\n",
            "Test set\n",
            "  Loss: 0.154\n",
            "  Accuracy: 0.963\n",
            "112/112 [==============================] - 1s 5ms/step\n",
            "Number Real news: 1964\n",
            "Number Fake news: 1606\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.96      0.96      0.96      1606\n",
            "     class 1       0.97      0.97      0.97      1964\n",
            "\n",
            "    accuracy                           0.96      3570\n",
            "   macro avg       0.96      0.96      0.96      3570\n",
            "weighted avg       0.96      0.96      0.96      3570\n",
            "\n",
            "\n",
            "Confusion Matrix\n",
            "              class_0 True  class_1 True\n",
            "class_0 pred          1540            66\n",
            "class_1 pred            66          1898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predict - Test set"
      ],
      "metadata": {
        "id": "LP0MiIH0-Mf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_result(X_test, Y_test, tok)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYETNYTv-NDl",
        "outputId": "9845698a-52ac-4641-968e-cddb7ba98e17"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132/132 [==============================] - 1s 6ms/step - loss: 0.1570 - accuracy: 0.9602\n",
            "Test set\n",
            "  Loss: 0.157\n",
            "  Accuracy: 0.960\n",
            "132/132 [==============================] - 0s 4ms/step\n",
            "Number Real news: 2265\n",
            "Number Fake news: 1935\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.95      0.96      0.96      1920\n",
            "     class 1       0.97      0.96      0.96      2280\n",
            "\n",
            "    accuracy                           0.96      4200\n",
            "   macro avg       0.96      0.96      0.96      4200\n",
            "weighted avg       0.96      0.96      0.96      4200\n",
            "\n",
            "\n",
            "Confusion Matrix\n",
            "              class_0 True  class_1 True\n",
            "class_0 pred          1844            76\n",
            "class_1 pred            91          2189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train model with  4 datasets**\n",
        "\n",
        "> Datasets: fake.csv, df_2016.csv, fake_Bisallion.csv and True_Bisallion.csv"
      ],
      "metadata": {
        "id": "UdvQVk6Y7xZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "real_news = pd.DataFrame(real_news1[\"text\"].append(real_news2[\"text\"], ignore_index = True))\n",
        "fake_news = pd.DataFrame(fake_news1[\"text\"].append(fake_news2[\"text\"], ignore_index = True))\n",
        "X_train, Y_train, X_valid, Y_valid, X_test, Y_test = merge_split_datasets(real_news, fake_news)"
      ],
      "metadata": {
        "id": "B092VQVap4te"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parameters tunning"
      ],
      "metadata": {
        "id": "sM0R6v1j4npk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 1000\n",
        "max_len = 150\n",
        "n_batchsize = 128\n",
        "n_epochs = 10\n"
      ],
      "metadata": {
        "id": "3QxJV4OtW42Z"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train model"
      ],
      "metadata": {
        "id": "K3np9KxP4wbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN()\n",
        "\n",
        "trained_model, tok = trainer(X_train, Y_train, max_words = max_words, max_len = max_len, n_batchsize = n_batchsize, n_epochs = n_epochs, model = model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwChq8wbW_bt",
        "outputId": "1e5b1545-18da-4864-8b67-9c64cbb6fe79"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 150)]             0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 150, 50)           50000     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                29440     \n",
            "                                                                 \n",
            " FC1 (Dense)                 (None, 256)               16640     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " out_layer (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 96,337\n",
            "Trainable params: 96,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "330/330 [==============================] - 8s 19ms/step - loss: 0.2253 - accuracy: 0.9129 - val_loss: 0.1657 - val_accuracy: 0.9455\n",
            "Epoch 2/10\n",
            "330/330 [==============================] - 4s 13ms/step - loss: 0.1466 - accuracy: 0.9475 - val_loss: 0.1823 - val_accuracy: 0.9314\n",
            "Epoch 3/10\n",
            "330/330 [==============================] - 4s 13ms/step - loss: 0.1325 - accuracy: 0.9524 - val_loss: 0.1507 - val_accuracy: 0.9500\n",
            "Epoch 4/10\n",
            "330/330 [==============================] - 4s 13ms/step - loss: 0.1217 - accuracy: 0.9564 - val_loss: 0.1455 - val_accuracy: 0.9483\n",
            "Epoch 5/10\n",
            "330/330 [==============================] - 4s 13ms/step - loss: 0.1105 - accuracy: 0.9597 - val_loss: 0.2300 - val_accuracy: 0.9398\n",
            "Epoch 6/10\n",
            "330/330 [==============================] - 5s 14ms/step - loss: 0.1001 - accuracy: 0.9632 - val_loss: 0.1642 - val_accuracy: 0.9454\n",
            "Epoch 7/10\n",
            "330/330 [==============================] - 4s 13ms/step - loss: 0.0960 - accuracy: 0.9654 - val_loss: 0.1395 - val_accuracy: 0.9514\n",
            "Epoch 8/10\n",
            "330/330 [==============================] - 5s 14ms/step - loss: 0.0891 - accuracy: 0.9676 - val_loss: 0.1437 - val_accuracy: 0.9491\n",
            "Epoch 9/10\n",
            "330/330 [==============================] - 4s 13ms/step - loss: 0.0852 - accuracy: 0.9694 - val_loss: 0.2023 - val_accuracy: 0.9485\n",
            "Epoch 10/10\n",
            "330/330 [==============================] - 4s 13ms/step - loss: 0.0814 - accuracy: 0.9708 - val_loss: 0.1389 - val_accuracy: 0.9558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predict - Valid set"
      ],
      "metadata": {
        "id": "zkla5Kgz41cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_result(X_valid, Y_valid, tok)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wSmSyeTxCPQ",
        "outputId": "35e820b0-4373-4df2-e634-5d416e854134"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 5ms/step - loss: 0.1416 - accuracy: 0.9580\n",
            "Test set\n",
            "  Loss: 0.142\n",
            "  Accuracy: 0.958\n",
            "291/291 [==============================] - 1s 4ms/step\n",
            "Number Real news: 4889\n",
            "Number Fake news: 4405\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.98      0.94      0.96      4593\n",
            "     class 1       0.94      0.98      0.96      4701\n",
            "\n",
            "    accuracy                           0.96      9294\n",
            "   macro avg       0.96      0.96      0.96      9294\n",
            "weighted avg       0.96      0.96      0.96      9294\n",
            "\n",
            "\n",
            "Confusion Matrix\n",
            "              class_0 True  class_1 True\n",
            "class_0 pred          4304           289\n",
            "class_1 pred           101          4600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predict - test set"
      ],
      "metadata": {
        "id": "1aH96O7D46bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_result(X_test, Y_test, tok)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV50mB5euziX",
        "outputId": "9ca19453-9ebd-434e-c0f1-b5930414b94e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "342/342 [==============================] - 2s 5ms/step - loss: 0.1330 - accuracy: 0.9570\n",
            "Test set\n",
            "  Loss: 0.133\n",
            "  Accuracy: 0.957\n",
            "342/342 [==============================] - 1s 4ms/step\n",
            "Number Real news: 5707\n",
            "Number Fake news: 5228\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.97      0.94      0.96      5406\n",
            "     class 1       0.94      0.97      0.96      5529\n",
            "\n",
            "    accuracy                           0.96     10935\n",
            "   macro avg       0.96      0.96      0.96     10935\n",
            "weighted avg       0.96      0.96      0.96     10935\n",
            "\n",
            "\n",
            "Confusion Matrix\n",
            "              class_0 True  class_1 True\n",
            "class_0 pred          5082           324\n",
            "class_1 pred           146          5383\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}