{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thaisbeham/Applied_deep_learning/blob/main/Assigment2_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM - Fake News detection\n",
        "\n",
        "Fake - 0\n",
        "Real - 1"
      ],
      "metadata": {
        "id": "OzFQgCpKtafy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vvy4rxvLKY6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfzdqQ4HKfSE",
        "outputId": "86586563-de4f-4feb-c302-4ca20adbfe54"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "#from utils import merge_datasets, smaller_set\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from matplotlib import pyplot as plt\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding,Dense,LSTM,Dropout,Flatten,BatchNormalization,Conv1D,GlobalMaxPooling1D,MaxPooling1D, GlobalAveragePooling1D\n",
        "from keras.optimizers import  SGD\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import Adam\n",
        "from keras import regularizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.preprocessing import sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#from hyperas.distributions import uniform\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras import regularizers\n",
        "import string\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing import sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "91HtHS8vKXCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read data"
      ],
      "metadata": {
        "id": "ZeEUBxOQsDWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_news(path, column_text_name):\n",
        "  news = pd.read_csv(path)\n",
        "  news[column_text_name] = news[column_text_name].astype(str)\n",
        "  return news\n",
        "\n",
        "def merge_split_datasets(real, fake, n_testsize = 0.15):\n",
        "    #take unique values from real data\n",
        "    real = real.drop_duplicates(subset = ['sentence'])\n",
        "\n",
        "    # take 13000 rows from real data\n",
        "    real = real.sample(n = 13000, random_state= 2, axis = 0)\n",
        "\n",
        "    # add column label\n",
        "    real['label'] = 1\n",
        "    fake['label'] = 0\n",
        "\n",
        "    real = real[['sentence', 'label']]\n",
        "    fake = fake[['text', 'label']]\n",
        "    real.rename(columns = {'sentence': 'text'}, inplace = True)\n",
        "\n",
        "    #merge real and fake\n",
        "    # use only the sentence column on fake\n",
        "    merged = pd.DataFrame(real.append(fake, ignore_index = True))\n",
        "    merged = merged.sample(frac = 1, random_state= 1, ignore_index = True)#.reset_index()\n",
        "\n",
        "    train, test = train_test_split(merged, test_size = n_testsize, random_state = 1)\n",
        "\n",
        "    X_test = test['text']\n",
        "    Y_test = test['label']\n",
        "\n",
        "    #create validation set\n",
        "    X = train['text']\n",
        "    Y = train['label'].astype(int)    \n",
        "    X_train,X_valid,Y_train,Y_valid = train_test_split(X,Y,test_size=0.15, random_state=42)\n",
        "\n",
        "    return X_train, Y_train, X_valid, Y_valid, X_test, Y_test\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JKzSXRq2lSJ4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_news = read_news(\"/content/drive/MyDrive/dados_/fake.csv\", \"text\")\n",
        "real_news = read_news(\"/content/drive/MyDrive/dados_/df_2016.csv\", \"sentence\")\n",
        "\n",
        "X_train, Y_train, X_valid, Y_valid, X_test, Y_test = merge_split_datasets(real_news, fake_news)\n",
        "\n",
        "#fake_news = pd.read_csv(\"/content/drive/MyDrive/dados_/fake.csv\")\n",
        "#fake_news.text=fake_news.text.astype(str)\n",
        "#real_news = pd.read_csv(\"/content/drive/MyDrive/dados_/df_2016.csv\")\n",
        "#real_news.sentence =real_news.sentence.astype(str)"
      ],
      "metadata": {
        "id": "xv6G6AP6TXRN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#parameters tunning\n",
        "max_words = 1000\n",
        "max_len = 150\n",
        "n_batchsize = 128\n",
        "n_epochs = 10\n",
        "\n",
        "#tokenizer\n",
        "tok = Tokenizer(num_words=max_words)\n",
        "tok.fit_on_texts(X_train)\n",
        "sequences = tok.texts_to_sequences(X_train)\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
      ],
      "metadata": {
        "id": "3QxJV4OtW42Z"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RNN():\n",
        "    inputs = Input(name='inputs',shape=[max_len])\n",
        "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
        "    layer = LSTM(64)(layer)\n",
        "    layer = Dense(256,name='FC1')(layer)\n",
        "    layer = Activation('relu')(layer)\n",
        "    layer = Dropout(0.5)(layer)\n",
        "    layer = Dense(1,name='out_layer')(layer)\n",
        "    layer = Activation('sigmoid')(layer)\n",
        "    model = Model(inputs=inputs,outputs=layer)\n",
        "    return model"
      ],
      "metadata": {
        "id": "Y1wYCCzqW45h"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN()\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu2yu5htW_ZE",
        "outputId": "7a727c7d-09c8-492c-b1d6-034c0ba36178"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 150)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 150, 50)           50000     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                29440     \n",
            "                                                                 \n",
            " FC1 (Dense)                 (None, 256)               16640     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " out_layer (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 96,337\n",
            "Trainable params: 96,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(sequences_matrix,Y_train,batch_size=n_batchsize,epochs=n_epochs,\n",
        "          validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwChq8wbW_bt",
        "outputId": "b35a0d1f-6e11-422d-c387-0bbc8b5bba35"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "118/118 [==============================] - 9s 18ms/step - loss: 0.1979 - accuracy: 0.9254 - val_loss: 0.1184 - val_accuracy: 0.9563\n",
            "Epoch 2/10\n",
            "118/118 [==============================] - 2s 13ms/step - loss: 0.0982 - accuracy: 0.9661 - val_loss: 0.0956 - val_accuracy: 0.9678\n",
            "Epoch 3/10\n",
            "118/118 [==============================] - 2s 13ms/step - loss: 0.0804 - accuracy: 0.9713 - val_loss: 0.0871 - val_accuracy: 0.9697\n",
            "Epoch 4/10\n",
            "118/118 [==============================] - 2s 15ms/step - loss: 0.0711 - accuracy: 0.9746 - val_loss: 0.0939 - val_accuracy: 0.9697\n",
            "Epoch 5/10\n",
            "118/118 [==============================] - 2s 19ms/step - loss: 0.0646 - accuracy: 0.9760 - val_loss: 0.1073 - val_accuracy: 0.9707\n",
            "Epoch 6/10\n",
            "118/118 [==============================] - 2s 15ms/step - loss: 0.0572 - accuracy: 0.9787 - val_loss: 0.0875 - val_accuracy: 0.9721\n",
            "Epoch 7/10\n",
            "118/118 [==============================] - 2s 13ms/step - loss: 0.0520 - accuracy: 0.9803 - val_loss: 0.0827 - val_accuracy: 0.9705\n",
            "Epoch 8/10\n",
            "118/118 [==============================] - 2s 13ms/step - loss: 0.0487 - accuracy: 0.9816 - val_loss: 0.1155 - val_accuracy: 0.9657\n",
            "Epoch 9/10\n",
            "118/118 [==============================] - 2s 13ms/step - loss: 0.0444 - accuracy: 0.9830 - val_loss: 0.0960 - val_accuracy: 0.9667\n",
            "Epoch 10/10\n",
            "118/118 [==============================] - 2s 13ms/step - loss: 0.0418 - accuracy: 0.9846 - val_loss: 0.0971 - val_accuracy: 0.9702\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff6a07fed90>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_result(X_test, Y_test):\n",
        "  test_sequences = tok.texts_to_sequences(X_test)\n",
        "  test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n",
        "  accr = model.evaluate(test_sequences_matrix,Y_test)\n",
        "  print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n",
        "  predict_labels = model.predict(test_sequences_matrix) \n",
        "\n",
        "  # convert the range predicition into 0s or 1s\n",
        "  Y_pred =[ 1 if i>0.5 else 0 for i in predict_labels  ] \n",
        "\n",
        "  print(\"Number Real news:\",sum(Y_pred))\n",
        "  print(\"Number Fake news:\",len(Y_pred)-sum(Y_pred))\n",
        "  print()\n",
        "  print(\"Classification Report\")\n",
        "  print(classification_report(Y_test, Y_pred, target_names = ['class 0', 'class 1']))\n",
        "  print()\n",
        "  print(\"Confusion Matrix\")\n",
        "  matrix=confusion_matrix(Y_test,Y_pred,labels=[0,1])\n",
        "  cm=pd.DataFrame(matrix,index=['class_0 pred','class_1 pred'],columns=['class_0 True','class_1 True'])\n",
        "  print(cm)\n",
        "\n"
      ],
      "metadata": {
        "id": "4I2v-TqlXOkk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict on validation set\n",
        "\n",
        "predict_result(X_valid, Y_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wSmSyeTxCPQ",
        "outputId": "1ddc8067-520d-421b-92b6-9bec3e66948d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1385 - accuracy: 0.9602\n",
            "Test set\n",
            "  Loss: 0.138\n",
            "  Accuracy: 0.960\n",
            "104/104 [==============================] - 1s 4ms/step\n",
            "Number Real news: 1701\n",
            "Number Fake news: 1614\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.98      0.94      0.96      1670\n",
            "     class 1       0.94      0.98      0.96      1645\n",
            "\n",
            "    accuracy                           0.96      3315\n",
            "   macro avg       0.96      0.96      0.96      3315\n",
            "weighted avg       0.96      0.96      0.96      3315\n",
            "\n",
            "\n",
            "Confusion Matrix\n",
            "              class_0 True  class_1 True\n",
            "class_0 pred          1576            94\n",
            "class_1 pred            38          1607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict on test set\n",
        "\n",
        "predict_result(X_test, Y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV50mB5euziX",
        "outputId": "0101e446-f6e1-439c-c320-93a1ecae0e29"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "122/122 [==============================] - 1s 6ms/step - loss: 0.1085 - accuracy: 0.9667\n",
            "Test set\n",
            "  Loss: 0.109\n",
            "  Accuracy: 0.967\n",
            "122/122 [==============================] - 1s 4ms/step\n",
            "Number Real news: 2057\n",
            "Number Fake news: 1843\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.98      0.95      0.97      1891\n",
            "     class 1       0.96      0.98      0.97      2009\n",
            "\n",
            "    accuracy                           0.97      3900\n",
            "   macro avg       0.97      0.97      0.97      3900\n",
            "weighted avg       0.97      0.97      0.97      3900\n",
            "\n",
            "\n",
            "Confusion Matrix\n",
            "              class_0 True  class_1 True\n",
            "class_0 pred          1802            89\n",
            "class_1 pred            41          1968\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}