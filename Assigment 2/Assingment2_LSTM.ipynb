{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thaisbeham/Applied_deep_learning/blob/main/Assigment%202/Assigment2_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM - Fake News detection\n",
        "\n",
        "Fake - 0\n",
        "Real - 1"
      ],
      "metadata": {
        "id": "OzFQgCpKtafy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vvy4rxvLKY6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfzdqQ4HKfSE",
        "outputId": "fb000298-1e47-4404-804e-42c901a23efa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "# from utils import merge_datasets, smaller_set\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from matplotlib import pyplot as plt\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.layers import (\n",
        "    Embedding,\n",
        "    Dense,\n",
        "    LSTM,\n",
        "    Dropout,\n",
        "    Flatten,\n",
        "    BatchNormalization,\n",
        "    Conv1D,\n",
        "    GlobalMaxPooling1D,\n",
        "    MaxPooling1D,\n",
        "    GlobalAveragePooling1D,\n",
        ")\n",
        "from keras.optimizers import SGD\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import Adam\n",
        "from keras import regularizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.preprocessing import sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# from hyperas.distributions import uniform\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras import regularizers\n",
        "import string\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing import sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from keras import callbacks\n",
        "from keras.utils import plot_model\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "91HtHS8vKXCk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "707458ab-e562-48cf-e6f8-a969f723a166"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions"
      ],
      "metadata": {
        "id": "ZeEUBxOQsDWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "def read_news(path, column_text_name):\n",
        "    news = pd.read_csv(path)\n",
        "    news[column_text_name] = news[column_text_name].astype(str)\n",
        "    if column_text_name != \"text\":\n",
        "        news.rename(columns={column_text_name: \"text\"}, inplace=True)\n",
        "\n",
        "    return news\n",
        "\n",
        "\n",
        "def merge_split_datasets(real, fake, n_testsize=0.15):\n",
        "\n",
        "    # add column label\n",
        "    real[\"label\"] = 1\n",
        "    fake[\"label\"] = 0\n",
        "\n",
        "    real = real[[\"text\", \"label\"]]\n",
        "    fake = fake[[\"text\", \"label\"]]\n",
        "\n",
        "    # merge real and fake\n",
        "    # use only the sentence column on fake\n",
        "    merged = pd.DataFrame(real.append(fake, ignore_index=True))\n",
        "    merged = merged.dropna()\n",
        "\n",
        "    # shuffle dataset\n",
        "    merged = merged.sample(frac=1, random_state=1, ignore_index=True)  # .reset_index()\n",
        "\n",
        "    merged[\"text\"].dropna(inplace=True)\n",
        "    merged[\"text\"] = merged[\"text\"].astype(str)\n",
        "\n",
        "    # remove stopwords\n",
        "    tokens = merged[\"text\"].apply(word_tokenize)\n",
        "    tokens = tokens.astype(str)\n",
        "    tokens = tokens.apply(str)\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    filtered_sentence = [w for w in tokens if not w.lower() in stop_words]\n",
        "\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "        filtered_sentence, merged[\"label\"], test_size=n_testsize, random_state=1\n",
        "    )\n",
        "\n",
        "    X_train, X_valid, Y_train, Y_valid = train_test_split(\n",
        "        X_train, Y_train, test_size=0.15, random_state=42\n",
        "    )\n",
        "\n",
        "    return X_train, Y_train, X_valid, Y_valid, X_test, Y_test\n",
        "\n",
        "\n",
        "def RNN(max_tokens, max_len, dropout):\n",
        "    inputs = Input(name=\"inputs\", shape=[max_len])\n",
        "    layer = Embedding(max_tokens, 50, input_length=max_len)(inputs)\n",
        "    layer = LSTM(64)(layer)\n",
        "    layer = Dense(256, name=\"FC1\")(layer)\n",
        "    layer = Activation(\"relu\")(layer)\n",
        "    layer = Dropout(dropout)(layer)\n",
        "    layer = Dense(1, name=\"out_layer\")(layer)\n",
        "    layer = Activation(\"sigmoid\")(layer)\n",
        "    model = Model(inputs=inputs, outputs=layer)\n",
        "    return model\n",
        "\n",
        "\n",
        "def predict_result(X_test, Y_test, model, tok):\n",
        "    test_sequences = tok.texts_to_sequences(X_test)\n",
        "    test_sequences_matrix = sequence.pad_sequences(test_sequences, maxlen=max_len)\n",
        "    accr = model.evaluate(test_sequences_matrix, Y_test)\n",
        "    print(\"Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}\".format(accr[0], accr[1]))\n",
        "    predict_labels = model.predict(test_sequences_matrix)\n",
        "\n",
        "    # convert the range predicition into 0s or 1s\n",
        "    Y_pred = [1 if i > 0.5 else 0 for i in predict_labels]\n",
        "\n",
        "    print(\"Number Real news:\", sum(Y_pred))\n",
        "    print(\"Number Fake news:\", len(Y_pred) - sum(Y_pred))\n",
        "    print()\n",
        "    print(\"Classification Report\")\n",
        "    print(classification_report(Y_test, Y_pred, target_names=[\"class 0\", \"class 1\"]))\n",
        "    print()\n",
        "    print(\"Confusion Matrix\")\n",
        "    matrix = confusion_matrix(Y_test, Y_pred, labels=[0, 1])\n",
        "    cm = pd.DataFrame(\n",
        "        matrix,\n",
        "        index=[\"class_0 pred\", \"class_1 pred\"],\n",
        "        columns=[\"class_0 True\", \"class_1 True\"],\n",
        "    )\n",
        "    print(cm)\n",
        "    return\n",
        "\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_accuracy\", verbose=1, patience=3\n",
        ")\n",
        "\n",
        "\n",
        "def trainer(X_train, Y_train, max_words, max_len, n_batchsize, n_epochs, model):\n",
        "    tok = Tokenizer(\n",
        "        num_words=max_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True\n",
        "    )\n",
        "    tok.fit_on_texts(X_train)\n",
        "    sequences = tok.texts_to_sequences(X_train)\n",
        "    sequences_matrix = sequence.pad_sequences(sequences, maxlen=max_len)\n",
        "    print(\"Found %s unique tokens.\" % len(sequences_matrix))\n",
        "    model.summary()\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=RMSprop(), metrics=[\"accuracy\"])\n",
        "    model.fit(\n",
        "        sequences_matrix,\n",
        "        Y_train,\n",
        "        batch_size=n_batchsize,\n",
        "        epochs=n_epochs,\n",
        "        validation_split=0.2,\n",
        "        callbacks=[earlystop],\n",
        "    )\n",
        "\n",
        "    return model, tok"
      ],
      "metadata": {
        "id": "JKzSXRq2lSJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read datasets"
      ],
      "metadata": {
        "id": "9ceouWvH4YrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BS Detector\n",
        "fake_news1 = read_news(\"/content/drive/MyDrive/dados_/fake.csv\", \"text\")\n",
        "# ISOT Dataset\n",
        "fake_news2 = read_news(\"/content/drive/MyDrive/dados_/Fake_bisaillon.csv\", \"text\")\n",
        "\n",
        "# New York Times\n",
        "real_news1 = read_news(\"/content/drive/MyDrive/dados_/df_2016.csv\", \"sentence\")\n",
        "# Reuters.com\n",
        "real_news2 = read_news(\"/content/drive/MyDrive/dados_/True_bisaillon.csv\", \"text\")\n",
        "\n",
        "# shape of each dataset\n",
        "print(\"Shape of each datasset\")\n",
        "print(\n",
        "    \"fake_news1: \",\n",
        "    np.shape(fake_news1),\n",
        "    \"\\nfake_news2: \",\n",
        "    np.shape(fake_news2),\n",
        "    \"\\nreal_news1: \",\n",
        "    np.shape(real_news1),\n",
        "    \"\\nreal_news2: \",\n",
        "    np.shape(real_news2),\n",
        ")\n",
        "real_news1_smallset = real_news1.sample(n=15000, random_state=2, axis=0)\n",
        "print(\"real_news1_smallset:\", np.shape(real_news1_smallset))\n",
        "\n",
        "# separate the location of the news from the news text (e.g. \"WASHINGTON (Reuters)\")\n",
        "real_news2[[\"loc\", \"text\"]] = real_news2[\"text\"].str.split(\"-\", 1, expand=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv6G6AP6TXRN",
        "outputId": "e3f0bf56-5201-4466-f673-cca68c8fd36a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fake_news1:  (12999, 20) \n",
            "fake_news2:  (23481, 4) \n",
            "real_news1:  (105606, 3) \n",
            "real_news2:  (21417, 4)\n",
            "real_news1 small set: (15000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train model with 2 datasets**\n",
        "> Datasets BS Detector and NY Times"
      ],
      "metadata": {
        "id": "f8h7IHbTMNeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train, X_valid, Y_valid, X_test, Y_test = merge_split_datasets(\n",
        "    real_news1, fake_news1\n",
        ")"
      ],
      "metadata": {
        "id": "whp8fIVsMMpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parameters tunning"
      ],
      "metadata": {
        "id": "e6gKmUdZMMaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 1000\n",
        "max_len = 300\n",
        "n_batchsize = 128\n",
        "n_epochs = 20\n",
        "dropout = 0.2"
      ],
      "metadata": {
        "id": "KwfRpNEQNXRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train"
      ],
      "metadata": {
        "id": "Q5DuJkpANjBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN(max_tokens=max_words, max_len=max_len, dropout=dropout)\n",
        "\n",
        "\n",
        "plot_model(model, \"model.png\")\n",
        "trained_model, tok = trainer(\n",
        "    X_train,\n",
        "    Y_train,\n",
        "    max_words=max_words,\n",
        "    max_len=max_len,\n",
        "    n_batchsize=n_batchsize,\n",
        "    n_epochs=n_epochs,\n",
        "    model=model,\n",
        ")"
      ],
      "metadata": {
        "id": "SeHUxroRNdJk",
        "outputId": "9faa77fd-610d-48c8-bf2f-31ef8849c2f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 85691 unique tokens.\n",
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 500)]             0         \n",
            "                                                                 \n",
            " embedding_10 (Embedding)    (None, 500, 50)           100000    \n",
            "                                                                 \n",
            " lstm_10 (LSTM)              (None, 64)                29440     \n",
            "                                                                 \n",
            " FC1 (Dense)                 (None, 256)               16640     \n",
            "                                                                 \n",
            " activation_20 (Activation)  (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " out_layer (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            " activation_21 (Activation)  (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 146,337\n",
            "Trainable params: 146,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "536/536 [==============================] - 19s 31ms/step - loss: 0.0707 - accuracy: 0.9800 - val_loss: 0.0384 - val_accuracy: 0.9884\n",
            "Epoch 2/20\n",
            "536/536 [==============================] - 16s 30ms/step - loss: 0.0296 - accuracy: 0.9904 - val_loss: 0.0263 - val_accuracy: 0.9910\n",
            "Epoch 3/20\n",
            "536/536 [==============================] - 16s 30ms/step - loss: 0.0239 - accuracy: 0.9922 - val_loss: 0.0242 - val_accuracy: 0.9922\n",
            "Epoch 4/20\n",
            "536/536 [==============================] - 16s 30ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.0217 - val_accuracy: 0.9929\n",
            "Epoch 5/20\n",
            "536/536 [==============================] - 16s 30ms/step - loss: 0.0169 - accuracy: 0.9941 - val_loss: 0.0248 - val_accuracy: 0.9911\n",
            "Epoch 6/20\n",
            "536/536 [==============================] - 16s 30ms/step - loss: 0.0150 - accuracy: 0.9945 - val_loss: 0.0248 - val_accuracy: 0.9935\n",
            "Epoch 7/20\n",
            "536/536 [==============================] - 19s 36ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 0.0221 - val_accuracy: 0.9936\n",
            "Epoch 8/20\n",
            "536/536 [==============================] - 16s 30ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.0261 - val_accuracy: 0.9923\n",
            "Epoch 9/20\n",
            "536/536 [==============================] - 18s 34ms/step - loss: 0.0108 - accuracy: 0.9959 - val_loss: 0.0238 - val_accuracy: 0.9933\n",
            "Epoch 10/20\n",
            "536/536 [==============================] - 16s 31ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0253 - val_accuracy: 0.9925\n",
            "Epoch 10: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predict - Valid set"
      ],
      "metadata": {
        "id": "AYfBMgFKOMvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_result(X_valid, Y_valid, trained_model, tok)"
      ],
      "metadata": {
        "id": "hd6gYeY-OMeW",
        "outputId": "0425f68e-acba-4dbf-c31f-2b01e2033d3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112/112 [==============================] - 0s 4ms/step - loss: 0.1367 - accuracy: 0.9703\n",
            "Test set\n",
            "  Loss: 0.137\n",
            "  Accuracy: 0.970\n",
            "112/112 [==============================] - 1s 6ms/step\n",
            "Number Real news: 1978\n",
            "Number Fake news: 1592\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.97      0.96      0.97      1606\n",
            "     class 1       0.97      0.98      0.97      1964\n",
            "\n",
            "    accuracy                           0.97      3570\n",
            "   macro avg       0.97      0.97      0.97      3570\n",
            "weighted avg       0.97      0.97      0.97      3570\n",
            "\n",
            "\n",
            "Confusion Matrix\n",
            "              class_0 True  class_1 True\n",
            "class_0 pred          1546            60\n",
            "class_1 pred            46          1918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test higher number of words and longer sentence lenght"
      ],
      "metadata": {
        "id": "blwr6YW5yKL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 5000\n",
        "max_len = 1000\n",
        "n_batchsize = 128\n",
        "n_epochs = 20\n",
        "dropout = 0.2\n",
        "\n",
        "model_higher = RNN(max_tokens=max_words, max_len=max_len, dropout=dropout)\n",
        "\n",
        "trained_model_higher, tok = trainer(\n",
        "    X_train,\n",
        "    Y_train,\n",
        "    max_words=max_words,\n",
        "    max_len=max_len,\n",
        "    n_batchsize=n_batchsize,\n",
        "    n_epochs=n_epochs,\n",
        "    model=model_higher,\n",
        ")\n",
        "predict_result(X_valid, Y_valid, trained_model_higher, tok)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmelI82nUFtp",
        "outputId": "71fec9a7-1d25-4a0c-f3cc-c576d6b194c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 118128 unique tokens.\n",
            "Model: \"model_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 1000)]            0         \n",
            "                                                                 \n",
            " embedding_13 (Embedding)    (None, 1000, 50)          250000    \n",
            "                                                                 \n",
            " lstm_13 (LSTM)              (None, 64)                29440     \n",
            "                                                                 \n",
            " FC1 (Dense)                 (None, 256)               16640     \n",
            "                                                                 \n",
            " activation_26 (Activation)  (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " out_layer (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            " activation_27 (Activation)  (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 296,337\n",
            "Trainable params: 296,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "739/739 [==============================] - 44s 57ms/step - loss: 0.1123 - accuracy: 0.9624 - val_loss: 0.0692 - val_accuracy: 0.9817\n",
            "Epoch 2/20\n",
            "739/739 [==============================] - 41s 55ms/step - loss: 0.0566 - accuracy: 0.9819 - val_loss: 0.0493 - val_accuracy: 0.9845\n",
            "Epoch 3/20\n",
            "739/739 [==============================] - 42s 56ms/step - loss: 0.0450 - accuracy: 0.9856 - val_loss: 0.0588 - val_accuracy: 0.9804\n",
            "Epoch 4/20\n",
            "739/739 [==============================] - 41s 56ms/step - loss: 0.0361 - accuracy: 0.9887 - val_loss: 0.0440 - val_accuracy: 0.9876\n",
            "Epoch 5/20\n",
            "739/739 [==============================] - 43s 58ms/step - loss: 0.0323 - accuracy: 0.9895 - val_loss: 0.0487 - val_accuracy: 0.9859\n",
            "Epoch 6/20\n",
            "739/739 [==============================] - 42s 57ms/step - loss: 0.0295 - accuracy: 0.9908 - val_loss: 0.0410 - val_accuracy: 0.9878\n",
            "Epoch 7/20\n",
            "739/739 [==============================] - 45s 61ms/step - loss: 0.0263 - accuracy: 0.9922 - val_loss: 0.0540 - val_accuracy: 0.9852\n",
            "Epoch 8/20\n",
            "739/739 [==============================] - 46s 62ms/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 0.0387 - val_accuracy: 0.9896\n",
            "Epoch 9/20\n",
            "739/739 [==============================] - 43s 58ms/step - loss: 0.0245 - accuracy: 0.9919 - val_loss: 0.0527 - val_accuracy: 0.9831\n",
            "Epoch 10/20\n",
            "739/739 [==============================] - 41s 55ms/step - loss: 0.0200 - accuracy: 0.9940 - val_loss: 0.0403 - val_accuracy: 0.9899\n",
            "Epoch 11/20\n",
            "739/739 [==============================] - 47s 63ms/step - loss: 0.0191 - accuracy: 0.9940 - val_loss: 0.0409 - val_accuracy: 0.9891\n",
            "Epoch 12/20\n",
            "739/739 [==============================] - 46s 62ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.0386 - val_accuracy: 0.9891\n",
            "Epoch 13/20\n",
            "739/739 [==============================] - 41s 55ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.0451 - val_accuracy: 0.9884\n",
            "Epoch 13: early stopping\n",
            "652/652 [==============================] - 10s 15ms/step - loss: 0.0508 - accuracy: 0.9862\n",
            "Test set\n",
            "  Loss: 0.051\n",
            "  Accuracy: 0.986\n",
            "652/652 [==============================] - 9s 14ms/step\n",
            "Number Real news: 16048\n",
            "Number Fake news: 4799\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.96      0.98      0.97      4704\n",
            "     class 1       0.99      0.99      0.99     16143\n",
            "\n",
            "    accuracy                           0.99     20847\n",
            "   macro avg       0.98      0.98      0.98     20847\n",
            "weighted avg       0.99      0.99      0.99     20847\n",
            "\n",
            "\n",
            "Confusion Matrix\n",
            "              class_0 True  class_1 True\n",
            "class_0 pred          4608            96\n",
            "class_1 pred           191         15952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second parameter test has higher valeus for vocabulary size ( max_words) and lenght of sentences (max_len). This choice resulted in even higher accuracy, which could indicate overfit of the data, therefore the previous parameters were the one choosen."
      ],
      "metadata": {
        "id": "EhxOkkiUWbE_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test lower number of words and setence lenght"
      ],
      "metadata": {
        "id": "lBtQOWGVyYHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 300\n",
        "max_len = 50\n",
        "n_batchsize = 128\n",
        "n_epochs = 20\n",
        "dropout = 0.2\n",
        "\n",
        "model_lower = RNN(max_tokens=max_words, max_len=max_len, dropout=dropout)\n",
        "\n",
        "trained_model_lower, tok = trainer(\n",
        "    X_train,\n",
        "    Y_train,\n",
        "    max_words=max_words,\n",
        "    max_len=max_len,\n",
        "    n_batchsize=n_batchsize,\n",
        "    n_epochs=n_epochs,\n",
        "    model=model_lower,\n",
        ")\n",
        "predict_result(X_valid, Y_valid, tok)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxcXxCFUyR59",
        "outputId": "b32d5e58-63cd-4a64-a6f8-5adc4c6c031a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20229 unique tokens.\n",
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 50)]              0         \n",
            "                                                                 \n",
            " embedding_8 (Embedding)     (None, 50, 50)            15000     \n",
            "                                                                 \n",
            " lstm_8 (LSTM)               (None, 64)                29440     \n",
            "                                                                 \n",
            " FC1 (Dense)                 (None, 256)               16640     \n",
            "                                                                 \n",
            " activation_16 (Activation)  (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " out_layer (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            " activation_17 (Activation)  (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 61,337\n",
            "Trainable params: 61,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "127/127 [==============================] - 3s 12ms/step - loss: 0.1882 - accuracy: 0.9372 - val_loss: 0.1104 - val_accuracy: 0.9567\n",
            "Epoch 2/10\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 0.1008 - accuracy: 0.9640 - val_loss: 0.1099 - val_accuracy: 0.9600\n",
            "Epoch 3/10\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 0.0780 - accuracy: 0.9706 - val_loss: 0.0882 - val_accuracy: 0.9711\n",
            "Epoch 4/10\n",
            "127/127 [==============================] - 2s 12ms/step - loss: 0.0703 - accuracy: 0.9736 - val_loss: 0.0758 - val_accuracy: 0.9721\n",
            "Epoch 5/10\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.0632 - accuracy: 0.9760 - val_loss: 0.0687 - val_accuracy: 0.9733\n",
            "Epoch 6/10\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.0572 - accuracy: 0.9779 - val_loss: 0.0981 - val_accuracy: 0.9644\n",
            "Epoch 7/10\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.0530 - accuracy: 0.9805 - val_loss: 0.0771 - val_accuracy: 0.9755\n",
            "Epoch 8/10\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.0503 - accuracy: 0.9810 - val_loss: 0.0685 - val_accuracy: 0.9748\n",
            "Epoch 9/10\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.0468 - accuracy: 0.9828 - val_loss: 0.0743 - val_accuracy: 0.9738\n",
            "Epoch 10/10\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.0440 - accuracy: 0.9828 - val_loss: 0.0636 - val_accuracy: 0.9768\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.1367 - accuracy: 0.9703\n",
            "Test set\n",
            "  Loss: 0.137\n",
            "  Accuracy: 0.970\n",
            "112/112 [==============================] - 1s 4ms/step\n",
            "Number Real news: 1978\n",
            "Number Fake news: 1592\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.97      0.96      0.97      1606\n",
            "     class 1       0.97      0.98      0.97      1964\n",
            "\n",
            "    accuracy                           0.97      3570\n",
            "   macro avg       0.97      0.97      0.97      3570\n",
            "weighted avg       0.97      0.97      0.97      3570\n",
            "\n",
            "\n",
            "Confusion Matrix\n",
            "              class_0 True  class_1 True\n",
            "class_0 pred          1546            60\n",
            "class_1 pred            46          1918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train model with 2 datasets with similar lenght**\n",
        "\n",
        "15000 rows for real news and 12999 for fake news\n",
        "\n",
        "Same datasets as before.\n"
      ],
      "metadata": {
        "id": "UBSus53f72RD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train, X_valid, Y_valid, X_test, Y_test = merge_split_datasets(\n",
        "    real_news1_smallset, fake_news1\n",
        ")"
      ],
      "metadata": {
        "id": "IUb82hpo71ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parameters tunning"
      ],
      "metadata": {
        "id": "PhbcwCGj83Lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 1000\n",
        "max_len = 150\n",
        "n_batchsize = 128\n",
        "n_epochs = 20\n",
        "dropout = 0.2"
      ],
      "metadata": {
        "id": "DYSQnx5k86_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train"
      ],
      "metadata": {
        "id": "1nTIOgOY9In6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN(max_tokens=max_words, max_len=max_len, dropout=dropout)\n",
        "\n",
        "trained_model, tok = trainer(\n",
        "    X_train,\n",
        "    Y_train,\n",
        "    max_words=max_words,\n",
        "    max_len=max_len,\n",
        "    n_batchsize=n_batchsize,\n",
        "    n_epochs=n_epochs,\n",
        "    model=model,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1jt7DSY9IR0",
        "outputId": "f2258088-c178-4005-c0bd-28b4ef09303f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20229 unique tokens.\n",
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 150)]             0         \n",
            "                                                                 \n",
            " embedding_11 (Embedding)    (None, 150, 50)           50000     \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (None, 64)                29440     \n",
            "                                                                 \n",
            " FC1 (Dense)                 (None, 256)               16640     \n",
            "                                                                 \n",
            " activation_22 (Activation)  (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " out_layer (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            " activation_23 (Activation)  (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 96,337\n",
            "Trainable params: 96,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "127/127 [==============================] - 4s 17ms/step - loss: 0.1903 - accuracy: 0.9331 - val_loss: 0.1107 - val_accuracy: 0.9590\n",
            "Epoch 2/20\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.0782 - accuracy: 0.9698 - val_loss: 0.0651 - val_accuracy: 0.9740\n",
            "Epoch 3/20\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 0.0548 - accuracy: 0.9791 - val_loss: 0.0569 - val_accuracy: 0.9778\n",
            "Epoch 4/20\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0448 - accuracy: 0.9830 - val_loss: 0.0524 - val_accuracy: 0.9807\n",
            "Epoch 5/20\n",
            "127/127 [==============================] - 3s 21ms/step - loss: 0.0373 - accuracy: 0.9854 - val_loss: 0.0551 - val_accuracy: 0.9810\n",
            "Epoch 6/20\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.0322 - accuracy: 0.9881 - val_loss: 0.0520 - val_accuracy: 0.9820\n",
            "Epoch 7/20\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.0262 - accuracy: 0.9900 - val_loss: 0.0931 - val_accuracy: 0.9698\n",
            "Epoch 8/20\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.0291 - accuracy: 0.9903 - val_loss: 0.0525 - val_accuracy: 0.9822\n",
            "Epoch 9/20\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.0194 - accuracy: 0.9929 - val_loss: 0.0572 - val_accuracy: 0.9829\n",
            "Epoch 10/20\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.0166 - accuracy: 0.9936 - val_loss: 0.0684 - val_accuracy: 0.9825\n",
            "Epoch 11/20\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 0.0597 - val_accuracy: 0.9834\n",
            "Epoch 12/20\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.0722 - val_accuracy: 0.9822\n",
            "Epoch 13/20\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0929 - val_accuracy: 0.9822\n",
            "Epoch 14/20\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.1456 - val_accuracy: 0.9787\n",
            "Epoch 14: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predict - Valid set"
      ],
      "metadata": {
        "id": "fPD5h7X5-Lbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_result(X_valid, Y_valid, trained_model, tok)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ-1RJsU-MB_",
        "outputId": "62a9dd7b-b252-4684-c53e-51e4cc386a61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112/112 [==============================] - 1s 6ms/step - loss: 0.1759 - accuracy: 0.9770\n",
            "Test set\n",
            "  Loss: 0.176\n",
            "  Accuracy: 0.977\n",
            "112/112 [==============================] - 1s 5ms/step\n",
            "Number Real news: 2018\n",
            "Number Fake news: 1552\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.99      0.96      0.97      1606\n",
            "     class 1       0.97      0.99      0.98      1964\n",
            "\n",
            "    accuracy                           0.98      3570\n",
            "   macro avg       0.98      0.98      0.98      3570\n",
            "weighted avg       0.98      0.98      0.98      3570\n",
            "\n",
            "\n",
            "Confusion Matrix\n",
            "              class_0 True  class_1 True\n",
            "class_0 pred          1538            68\n",
            "class_1 pred            14          1950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train model with  4 datasets**\n",
        "\n",
        "> Datasets: \n",
        "\n",
        "Real: NEW York times and Reuters.com (ISOT dataset)\n",
        "\n",
        "Fake: BS Detector and fake news from ISOT Dataset"
      ],
      "metadata": {
        "id": "UdvQVk6Y7xZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real_news = pd.DataFrame(\n",
        "    real_news1[\"text\"].append(real_news2[\"text\"], ignore_index=True)\n",
        ")\n",
        "real_news = real_news.sample(frac=1, random_state=1, ignore_index=True)\n",
        "\n",
        "fake_news = pd.DataFrame(\n",
        "    fake_news1[\"text\"].append(fake_news2[\"text\"], ignore_index=True)\n",
        ")\n",
        "fake_news = fake_news.sample(frac=1, random_state=1, ignore_index=True)\n",
        "\n",
        "X_train, Y_train, X_valid, Y_valid, X_test, Y_test = merge_split_datasets(\n",
        "    real_news, fake_news\n",
        ")"
      ],
      "metadata": {
        "id": "B092VQVap4te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parameters tunning"
      ],
      "metadata": {
        "id": "sM0R6v1j4npk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 1000\n",
        "max_len = 150\n",
        "n_batchsize = 128\n",
        "n_epochs = 20\n",
        "dropout = 0.2"
      ],
      "metadata": {
        "id": "3QxJV4OtW42Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train model"
      ],
      "metadata": {
        "id": "K3np9KxP4wbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN(max_tokens=max_words, max_len=max_len, dropout=dropout)\n",
        "\n",
        "trained_model, tok = trainer(\n",
        "    X_train,\n",
        "    Y_train,\n",
        "    max_words=max_words,\n",
        "    max_len=max_len,\n",
        "    n_batchsize=n_batchsize,\n",
        "    n_epochs=n_epochs,\n",
        "    model=model,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwChq8wbW_bt",
        "outputId": "cfaed875-1969-46e5-8bab-e40d53afce90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 118128 unique tokens.\n",
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 150)]             0         \n",
            "                                                                 \n",
            " embedding_12 (Embedding)    (None, 150, 50)           50000     \n",
            "                                                                 \n",
            " lstm_12 (LSTM)              (None, 64)                29440     \n",
            "                                                                 \n",
            " FC1 (Dense)                 (None, 256)               16640     \n",
            "                                                                 \n",
            " activation_24 (Activation)  (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " out_layer (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            " activation_25 (Activation)  (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 96,337\n",
            "Trainable params: 96,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "739/739 [==============================] - 13s 15ms/step - loss: 0.1315 - accuracy: 0.9546 - val_loss: 0.1489 - val_accuracy: 0.9553\n",
            "Epoch 2/20\n",
            "739/739 [==============================] - 13s 18ms/step - loss: 0.0809 - accuracy: 0.9722 - val_loss: 0.0710 - val_accuracy: 0.9768\n",
            "Epoch 3/20\n",
            "739/739 [==============================] - 11s 15ms/step - loss: 0.0692 - accuracy: 0.9758 - val_loss: 0.0826 - val_accuracy: 0.9748\n",
            "Epoch 4/20\n",
            "739/739 [==============================] - 10s 14ms/step - loss: 0.0611 - accuracy: 0.9785 - val_loss: 0.0646 - val_accuracy: 0.9807\n",
            "Epoch 5/20\n",
            "739/739 [==============================] - 10s 14ms/step - loss: 0.0551 - accuracy: 0.9813 - val_loss: 0.0578 - val_accuracy: 0.9803\n",
            "Epoch 6/20\n",
            "739/739 [==============================] - 10s 13ms/step - loss: 0.0495 - accuracy: 0.9833 - val_loss: 0.0549 - val_accuracy: 0.9815\n",
            "Epoch 7/20\n",
            "739/739 [==============================] - 10s 14ms/step - loss: 0.0452 - accuracy: 0.9849 - val_loss: 0.0963 - val_accuracy: 0.9681\n",
            "Epoch 8/20\n",
            "739/739 [==============================] - 10s 13ms/step - loss: 0.0426 - accuracy: 0.9858 - val_loss: 0.0555 - val_accuracy: 0.9813\n",
            "Epoch 9/20\n",
            "739/739 [==============================] - 10s 13ms/step - loss: 0.0391 - accuracy: 0.9870 - val_loss: 0.0470 - val_accuracy: 0.9840\n",
            "Epoch 10/20\n",
            "739/739 [==============================] - 10s 14ms/step - loss: 0.0363 - accuracy: 0.9883 - val_loss: 0.0523 - val_accuracy: 0.9827\n",
            "Epoch 11/20\n",
            "739/739 [==============================] - 10s 14ms/step - loss: 0.0338 - accuracy: 0.9886 - val_loss: 0.0534 - val_accuracy: 0.9817\n",
            "Epoch 12/20\n",
            "739/739 [==============================] - 10s 14ms/step - loss: 0.0315 - accuracy: 0.9896 - val_loss: 0.0532 - val_accuracy: 0.9822\n",
            "Epoch 12: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predict - Valid set"
      ],
      "metadata": {
        "id": "zkla5Kgz41cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_result(X_valid, Y_valid, trained_model, tok)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wSmSyeTxCPQ",
        "outputId": "360774c7-fb03-47e6-d355-36b0c8d7db88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "652/652 [==============================] - 3s 5ms/step - loss: 0.0590 - accuracy: 0.9808\n",
            "Test set\n",
            "  Loss: 0.059\n",
            "  Accuracy: 0.981\n",
            "652/652 [==============================] - 3s 4ms/step\n",
            "Number Real news: 16135\n",
            "Number Fake news: 4712\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.96      0.96      0.96      4704\n",
            "     class 1       0.99      0.99      0.99     16143\n",
            "\n",
            "    accuracy                           0.98     20847\n",
            "   macro avg       0.97      0.97      0.97     20847\n",
            "weighted avg       0.98      0.98      0.98     20847\n",
            "\n",
            "\n",
            "Confusion Matrix\n",
            "              class_0 True  class_1 True\n",
            "class_0 pred          4508           196\n",
            "class_1 pred           204         15939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predict - test set"
      ],
      "metadata": {
        "id": "1aH96O7D46bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_result(X_test, Y_test, trained_model, tok)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV50mB5euziX",
        "outputId": "5b31c225-6dbd-4e6a-de5a-0cd927bec614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "767/767 [==============================] - 4s 5ms/step - loss: 0.0547 - accuracy: 0.9825\n",
            "Test set\n",
            "  Loss: 0.055\n",
            "  Accuracy: 0.982\n",
            "767/767 [==============================] - 3s 4ms/step\n",
            "Number Real news: 19151\n",
            "Number Fake news: 5375\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.96      0.96      0.96      5371\n",
            "     class 1       0.99      0.99      0.99     19155\n",
            "\n",
            "    accuracy                           0.98     24526\n",
            "   macro avg       0.97      0.97      0.97     24526\n",
            "weighted avg       0.98      0.98      0.98     24526\n",
            "\n",
            "\n",
            "Confusion Matrix\n",
            "              class_0 True  class_1 True\n",
            "class_0 pred          5158           213\n",
            "class_1 pred           217         18938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate requirements.txt\n",
        "\n",
        "from pip._internal.utils.misc import get_installed_distributions\n",
        "import sys\n",
        "\n",
        "def get_imported_packages():\n",
        "    p = get_installed_distributions()\n",
        "    p = {package.key:package.version for package in p}\n",
        "\n",
        "    imported_modules = set(sys.modules.keys())\n",
        "    \n",
        "    imported_modules.remove('pip')\n",
        "\n",
        "    modules = [(m, p[m]) for m in imported_modules if p.get(m, False)]\n",
        "\n",
        "    return modules\n",
        "\n",
        "\n",
        "def generate_requirements(filepath:str, modules):\n",
        "    with open(filepath, 'w') as f:\n",
        "        for module, version in modules:\n",
        "            f.write(f\"{module}=={version}\\n\")\n",
        "\n",
        "\n",
        "generate_requirements('requirements.txt', get_imported_packages())"
      ],
      "metadata": {
        "id": "srxm9FlNlwBp"
      },
      "execution_count": 11,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
